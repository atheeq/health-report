<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Health Report — LLM Browser Example</title>
    <style>
      body{font-family:system-ui,Segoe UI,Roboto,Helvetica,Arial,sans-serif;margin:16px;max-width:960px}
      .row{display:flex;gap:12px;align-items:center;margin:12px 0;flex-wrap:wrap}
      label{font-size:.9rem;color:#374151}
      input[type="text"],input[type="password"]{padding:6px 8px;border:1px solid #cbd5e1;border-radius:6px;min-width:260px}
      button{padding:8px 12px;border:1px solid #94a3b8;border-radius:6px;background:#fff;cursor:pointer}
      button:disabled{opacity:.5;cursor:not-allowed}
      .note{font-size:.9rem;color:#475569}
      iframe{width:100%;height:70vh;border:1px solid #e5e7eb;border-radius:8px}
      .warn{background:#fff7ed;border:1px solid #fed7aa;color:#7c2d12;padding:8px 10px;border-radius:8px}
    </style>
  </head>
  <body>
    <h1>Health Report — LLM (Browser)</h1>
    <p class="note">Demo of <code>renderHtmlLlm</code> in the browser. This calls an OpenAI-compatible chat API directly; most providers do not enable CORS. Use a secure proxy or a dev gateway that adds CORS and keeps your API key server-side.</p>
    <div class="warn">Security note: Never expose production API keys in the browser. Prefer a backend proxy.</div>

    <div class="row">
      <label>API Base URL <input id="baseUrl" type="text" placeholder="https://api.openai.com/v1" /></label>
      <label>API Key <input id="apiKey" type="password" placeholder="sk-..." /></label>
      <label>Model <input id="model" type="text" placeholder="gpt-4o" /></label>
      <label>Max Tokens <input id="maxTokens" type="text" placeholder="4000" /></label>
    </div>
    <div class="row">
      <input type="file" id="file" accept=".json,application/json" />
      <button id="btn-run">Generate LLM HTML (from file)</button>
      <button id="btn-sample">Generate LLM HTML (tests/fixtures sample)</button>
    </div>
    <iframe id="preview"></iframe>

    <script type="module">
      import { renderHtmlLlm } from '../../dist/esm/index.js';

      const preview = document.getElementById('preview');

      async function readJsonFile(f){ const t = await f.text(); return JSON.parse(t); }
      async function sampleBundle(){ const r = await fetch('../../tests/fixtures/fhir-bundle.json'); return await r.json(); }

      async function runWithInput(input){
        const baseUrl = document.getElementById('baseUrl').value || 'https://api.openai.com/v1';
        const apiKey = document.getElementById('apiKey').value;
        const model = document.getElementById('model').value || 'gpt-4o';
        const maxTokens = Number(document.getElementById('maxTokens').value || '4000');
        if (!apiKey) { alert('Enter an API key or use a proxy base URL that injects a key.'); return; }
        try {
          const html = await renderHtmlLlm(input, { llm: { enabled: true, baseUrl, apiKey, model, maxTokens, chunk: { maxChunkChars: 250000 } } });
          const doc = preview.contentWindow.document; doc.open(); doc.write(html); doc.close();
        } catch (e) {
          alert('LLM render failed: ' + (e?.message || e));
        }
      }

      document.getElementById('btn-run').addEventListener('click', async () => {
        const f = document.getElementById('file').files?.[0];
        if (!f) return alert('Choose a FHIR Bundle JSON file');
        const input = await readJsonFile(f);
        await runWithInput(input);
      });

      document.getElementById('btn-sample').addEventListener('click', async () => {
        const input = await sampleBundle();
        await runWithInput(input);
      });
    </script>
  </body>
  </html>

